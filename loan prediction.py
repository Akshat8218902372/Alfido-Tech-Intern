# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xvHJK47nbPIhHX_Ox-A5yx2RHeB30FVm
"""

# Loan Approval Prediction Model
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score

# Load data
print("Loading data...")
df = pd.read_csv('loan_prediction.csv')
print(f"\nFirst 5 rows:\n{df.head()}")
print(f"\nData shape: {df.shape}")

# Handle missing values
print("\nHandling missing values...")
print(f"Missing values before:\n{df.isnull().sum()}")

# Fill numerical missing values with median
num_cols = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History']
df[num_cols] = df[num_cols].fillna(df[num_cols].median())

# Fill categorical missing values with mode
cat_cols = ['Gender', 'Married', 'Dependents', 'Self_Employed']
df[cat_cols] = df[cat_cols].fillna(df[cat_cols].mode().iloc[0])

# Convert '3+' in Dependents to '3'
df['Dependents'] = df['Dependents'].replace('3+', '3')

print(f"\nMissing values after:\n{df.isnull().sum()}")

# EDA
print("\nExploratory Data Analysis:")
print(f"\nLoan Status distribution:\n{df['Loan_Status'].value_counts(normalize=True)}")
print(f"\nData description:\n{df.describe()}")

# Feature Engineering
print("\nCreating new features...")
df['TotalIncome'] = df['ApplicantIncome'] + df['CoapplicantIncome']
df['EMI'] = df['LoanAmount'] / df['Loan_Amount_Term']
df['IncomeToLoanRatio'] = df['TotalIncome'] / df['LoanAmount']

# Encode categorical variables
print("\nEncoding categorical variables...")
label_encoder = LabelEncoder()
df['Loan_Status'] = label_encoder.fit_transform(df['Loan_Status'])
cat_cols = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Property_Area']
df = pd.get_dummies(df, columns=cat_cols, drop_first=True)

# Prepare data for modeling
print("\nPreparing data for modeling...")
X = df.drop(['Loan_ID', 'Loan_Status'], axis=1)
y = df['Loan_Status']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale numerical features
scaler = StandardScaler()
num_cols = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term',
            'Credit_History', 'TotalIncome', 'EMI', 'IncomeToLoanRatio']
X_train[num_cols] = scaler.fit_transform(X_train[num_cols])
X_test[num_cols] = scaler.transform(X_test[num_cols])

# Train model
print("\nTraining Random Forest model...")
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Evaluate model
print("\nEvaluating model...")
y_pred = model.predict(X_test)
print(f"\nAccuracy: {accuracy_score(y_test, y_pred):.2f}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Feature importance
print("\nFeature Importance:")
importances = model.feature_importances_
features = X.columns
feature_importance = pd.DataFrame({'Feature': features, 'Importance': importances})
feature_importance = feature_importance.sort_values('Importance', ascending=False)
print(feature_importance.head(10))